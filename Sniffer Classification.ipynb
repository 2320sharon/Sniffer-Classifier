{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f44b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66810c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=os.getcwd()+os.sep+\"images\"\n",
    "imgs=glob.glob(dataset_path+os.sep+\"*.jpg\")\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b5c13",
   "metadata": {},
   "source": [
    "## Goal #1 Create a pipeline to preprocesses all the images\n",
    "1. convert images to grayscale\n",
    "2. Normalize the images\n",
    "3. Perform Data Augmentation\n",
    "4. Image Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca7869",
   "metadata": {},
   "source": [
    "## Create a image generator to apply augmentations to the imagery\n",
    "- standardizes the image sizes \n",
    "- applies zooms, flips, rotations to the imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587541d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255.,\n",
    "rotation_range=20,\n",
    "zoom_range=0.05,\n",
    "width_shift_range=0.05,\n",
    "height_shift_range=0.05,\n",
    "shear_range=0.05,\n",
    "horizontal_flip=True,\n",
    "fill_mode=\"nearest\",\n",
    "validation_split=0.20\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73ed02",
   "metadata": {},
   "source": [
    "# Read in the  csv file and transform in df\n",
    "1. read in the csv\n",
    "2. one hot encode the sorted labels\n",
    "3. Update the one hot encoded labels to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baaeaff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Sorted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-01-18-36-33_L5_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-11-18-52-32_L8_rgb.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-05-18-53-15_L8_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-10-14-18-23-57_L5_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-12-18-47-38_L8_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2018-11-24-18-46-00_L8_rgb.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2002-09-09-18-20-07_L5_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2016-10-01-18-46-19_L8_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2001-05-01-18-26-16_L5_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2014-04-03-18-46-16_L8_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename Sorted\n",
       "0    2009-12-01-18-36-33_L5_rgb.jpg   good\n",
       "1    2017-10-11-18-52-32_L8_rgb.jpg    bad\n",
       "2    2014-02-05-18-53-15_L8_rgb.jpg   good\n",
       "3    2003-10-14-18-23-57_L5_rgb.jpg   good\n",
       "4    2013-12-12-18-47-38_L8_rgb.jpg   good\n",
       "..                              ...    ...\n",
       "389  2018-11-24-18-46-00_L8_rgb.jpg    bad\n",
       "390  2002-09-09-18-20-07_L5_rgb.jpg   good\n",
       "391  2016-10-01-18-46-19_L8_rgb.jpg   good\n",
       "392  2001-05-01-18-26-16_L5_rgb.jpg   good\n",
       "393  2014-04-03-18-46-16_L8_rgb.jpg   good\n",
       "\n",
       "[394 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=os.getcwd()+os.sep+\"images\"\n",
    "labels=[\"good\",\"bad\"]\n",
    "df =  pd.read_csv(\"Sniffer_Output_17_03_2022_hr_17_03.csv\")\n",
    "df.drop(['index'],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d6fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 0, 'bad': 1}\n",
      "\n",
      " 0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "389    1\n",
      "390    0\n",
      "391    0\n",
      "392    0\n",
      "393    0\n",
      "Name: Sorted, Length: 394, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### map each label(good or bad) to an integer\n",
    "mapping = {}\n",
    "for x in range(len(labels)):\n",
    "  mapping[labels[x]] = x\n",
    "# outputs {'good': 0, 'bad': 1}\n",
    "print(mapping)\n",
    "# integer representation\n",
    "for x in range(len(df['Sorted'])):\n",
    "  df['Sorted'][x] = mapping[df['Sorted'][x]]\n",
    "print(\"\\n\",df['Sorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15b260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Filename Sorted\n",
      "0    2009-12-01-18-36-33_L5_rgb.jpg      0\n",
      "1    2017-10-11-18-52-32_L8_rgb.jpg      1\n",
      "2    2014-02-05-18-53-15_L8_rgb.jpg      0\n",
      "3    2003-10-14-18-23-57_L5_rgb.jpg      0\n",
      "4    2013-12-12-18-47-38_L8_rgb.jpg      0\n",
      "..                              ...    ...\n",
      "291  2017-06-14-18-45-46_L8_rgb.jpg      0\n",
      "292  2014-09-01-18-52-21_L8_rgb.jpg      0\n",
      "293  2005-06-13-18-33-36_L5_rgb.jpg      0\n",
      "294  2008-09-25-18-30-49_L5_rgb.jpg      0\n",
      "295  2005-04-10-18-33-11_L5_rgb.jpg      0\n",
      "\n",
      "[296 rows x 2 columns]\n",
      "                           Filename Sorted\n",
      "296  2002-10-11-18-19-06_L5_rgb.jpg      0\n",
      "297  2019-06-04-18-45-50_L8_rgb.jpg      0\n",
      "298  2021-07-27-18-46-06_L8_rgb.jpg      1\n",
      "299  2017-04-02-18-51-49_L8_rgb.jpg      1\n",
      "300  2016-09-06-18-52-28_L8_rgb.jpg      0\n",
      "..                              ...    ...\n",
      "389  2018-11-24-18-46-00_L8_rgb.jpg      1\n",
      "390  2002-09-09-18-20-07_L5_rgb.jpg      0\n",
      "391  2016-10-01-18-46-19_L8_rgb.jpg      0\n",
      "392  2001-05-01-18-26-16_L5_rgb.jpg      0\n",
      "393  2014-04-03-18-46-16_L8_rgb.jpg      0\n",
      "\n",
      "[98 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converted the sorted column to string otherwises data generator will not work\n",
    "df[\"Sorted\"]=df[\"Sorted\"].astype(str)\n",
    "# Split the dataframe into a train and test set into a .75 and .25 training and test set respectively\n",
    "traindf=df.iloc[:296,:] # get the first 296 rows\n",
    "testdf=df.iloc[296:,:] # get the  remaining 98 rows\n",
    "\n",
    "# Get the x and y column names from the csv file\n",
    "x_col_name=df.columns[0]\n",
    "y_col_name=df.columns[1]\n",
    "\n",
    "print(traindf)\n",
    "print(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf669819",
   "metadata": {},
   "source": [
    "## Flow the images from the dataframe\n",
    "- resize the images from 934 x 294 to 900x294\n",
    "- shuffle the images\n",
    "- divide the data into a training and validation subset\n",
    "- set a random seed\n",
    "- set the column names to check \n",
    "\n",
    "1. TASK: investigate class_mode\n",
    "2. TASK: modify the images target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b553451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=dataset_path,\n",
    "x_col=x_col_name, #image filenames\n",
    "y_col=y_col_name,   # class names in this case good/bad\n",
    "subset=\"training\",\n",
    "batch_size=37,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(900,250))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5232b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=train_datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=dataset_path,\n",
    "x_col=x_col_name, #image filenames\n",
    "y_col=y_col_name,   # class names in this case good/bad\n",
    "subset=\"validation\", #only difference is this\n",
    "batch_size=37, #296/8=37\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(900,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc3633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=testdf,\n",
    "directory=\"./images/\",\n",
    "x_col=x_col_name, #image filenames\n",
    "y_col=None,\n",
    "batch_size=14, #98/7=14\n",
    "seed=42,\n",
    "shuffle=False,  #shuffle must be false for validation dataset otherwise labels will not match\n",
    "class_mode=None,\n",
    "target_size=(900,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e874f",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "Create a simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825ea7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_model():\n",
    "#     model =  keras.Sequential()\n",
    "#     model.add(Conv2D(32,kernel_size=(3,3), padding= 'same',activation='relu',input_shape=(900, 250, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv2D(32, (3, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv2D(64, (3, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(512))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "#     model.compile(optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec859eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(900, 250, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a595226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 61s 8s/step - loss: 0.6465 - accuracy: 0.6900 - val_loss: 0.6051 - val_accuracy: 0.6757\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 38s 6s/step - loss: 0.5018 - accuracy: 0.7150 - val_loss: 0.3961 - val_accuracy: 0.7838\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 37s 6s/step - loss: 0.4454 - accuracy: 0.7100 - val_loss: 0.3501 - val_accuracy: 0.7568\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 36s 6s/step - loss: 0.4097 - accuracy: 0.7550 - val_loss: 0.2426 - val_accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 38s 6s/step - loss: 0.2988 - accuracy: 0.9000 - val_loss: 0.2118 - val_accuracy: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166c59d6f48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model()\n",
    "model.fit(train_generator,\n",
    "                    validation_data = train_generator,\n",
    "                    steps_per_epoch = train_generator.n//train_generator.batch_size,\n",
    "                    validation_steps = valid_generator.n//valid_generator.batch_size,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1758970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 2s/step - loss: 0.5627 - accuracy: 0.8305\n",
      "Test loss: 0.562666118144989\n",
      "Test accuracy: 0.8305084705352783\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(valid_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3542ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test scores to a file\n",
    "import csv\n",
    "csv_file_path=os.getcwd()+os.sep+\"test_results\"+os.sep+\"modelScores.csv\"\n",
    "if not os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as outcsv:\n",
    "        writer = csv.writer(outcsv)\n",
    "        writer.writerow([\"Accuracy\", \"Test Loss\", \"Model Description\"])\n",
    "elif os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, 'a', newline='') as outcsv:\n",
    "            writer = csv.writer(outcsv)\n",
    "            writer.writerow([score[1], score[0], \"redid entire model after research\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  keras.Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), padding='same',\n",
    "#                  input_shape=(32,32,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6167b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f151b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
