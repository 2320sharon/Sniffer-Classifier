{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f44b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66810c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=os.getcwd()+os.sep+\"images\"\n",
    "imgs=glob.glob(dataset_path+os.sep+\"*.jpg\")\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b5c13",
   "metadata": {},
   "source": [
    "## Goal #1 Create a pipeline to preprocesses all the images\n",
    "1. convert images to grayscale\n",
    "2. Normalize the images\n",
    "3. Perform Data Augmentation\n",
    "4. Image Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca7869",
   "metadata": {},
   "source": [
    "## Create a image generator to apply augmentations to the imagery\n",
    "- standardizes the image sizes \n",
    "- applies zooms, flips, rotations to the imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587541d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255.,\n",
    "rotation_range=20,\n",
    "zoom_range=0.05,\n",
    "width_shift_range=0.05,\n",
    "height_shift_range=0.05,\n",
    "shear_range=0.05,\n",
    "horizontal_flip=True,\n",
    "fill_mode=\"nearest\",\n",
    "validation_split=0.20\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73ed02",
   "metadata": {},
   "source": [
    "# Read in the  csv file and transform in df\n",
    "1. read in the csv\n",
    "2. one hot encode the sorted labels\n",
    "3. Update the one hot encoded labels to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaeaff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Filename', 'Sorted'], dtype='object')\n",
      "Dropping column Unnamed: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Sorted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-01-18-36-33_L5_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-11-18-52-32_L8_rgb.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-05-18-53-15_L8_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-10-14-18-23-57_L5_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-12-18-47-38_L8_rgb.jpg</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2021-09-21-19-04-08_S2.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2021-09-26-19-04-09_S2.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2021-10-01-19-04-08_S2.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2021-10-11-19-04-07_S2.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2021-12-15-19-04-20_S2.jpg</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename Sorted\n",
       "0    2009-12-01-18-36-33_L5_rgb.jpg   good\n",
       "1    2017-10-11-18-52-32_L8_rgb.jpg    bad\n",
       "2    2014-02-05-18-53-15_L8_rgb.jpg   good\n",
       "3    2003-10-14-18-23-57_L5_rgb.jpg   good\n",
       "4    2013-12-12-18-47-38_L8_rgb.jpg   good\n",
       "..                              ...    ...\n",
       "646      2021-09-21-19-04-08_S2.jpg    bad\n",
       "647      2021-09-26-19-04-09_S2.jpg    bad\n",
       "648      2021-10-01-19-04-08_S2.jpg    bad\n",
       "649      2021-10-11-19-04-07_S2.jpg    bad\n",
       "650      2021-12-15-19-04-20_S2.jpg    bad\n",
       "\n",
       "[651 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=os.getcwd()+os.sep+\"images\"\n",
    "labels=[\"good\",\"bad\"]\n",
    "df =  pd.read_csv(\"main.csv\")\n",
    "print(df.columns)\n",
    "if \"index\" in df.columns:\n",
    "    print(\"Dropping column index\")\n",
    "    df.drop(['index'],axis=1,inplace=True)\n",
    "if \"Unnamed: 0\"in df.columns:\n",
    "    print(\"Dropping column Unnamed: 0\")\n",
    "    df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d6fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 0, 'bad': 1}\n",
      "\n",
      " 0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "646    1\n",
      "647    1\n",
      "648    1\n",
      "649    1\n",
      "650    1\n",
      "Name: Sorted, Length: 651, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### map each label(good or bad) to an integer\n",
    "mapping = {}\n",
    "for x in range(len(labels)):\n",
    "  mapping[labels[x]] = x\n",
    "# outputs {'good': 0, 'bad': 1}\n",
    "print(mapping)\n",
    "# integer representation\n",
    "for x in range(len(df['Sorted'])):\n",
    "  df['Sorted'][x] = mapping[df['Sorted'][x]]\n",
    "print(\"\\n\",df['Sorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f15b260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Filename Sorted\n",
      "0                       2009-12-01-18-36-33_L5_rgb.jpg      0\n",
      "1                       2017-10-11-18-52-32_L8_rgb.jpg      1\n",
      "2                       2014-02-05-18-53-15_L8_rgb.jpg      0\n",
      "3                       2003-10-14-18-23-57_L5_rgb.jpg      0\n",
      "4                       2013-12-12-18-47-38_L8_rgb.jpg      0\n",
      "..                                                 ...    ...\n",
      "495  2018-12-10-15-27-23_L8_2022-03-31__09_hr_48_mi...      0\n",
      "496  2018-12-10-15-27-23_L8_2022-03-31__09_hr_49_mi...      1\n",
      "497                         2018-12-10-18-46-21_L8.jpg      1\n",
      "498                         2018-12-11-15-41-39_S2.jpg      0\n",
      "499  2018-12-11-15-41-39_S2_2022-03-31__09_hr_49_mi...      1\n",
      "\n",
      "[500 rows x 2 columns]\n",
      "                                              Filename Sorted\n",
      "500  2018-12-11-15-41-39_S2_2022-03-31__09_hr_50_mi...      0\n",
      "501  2018-12-11-15-41-39_S2_2022-03-31__09_hr_51_mi...      0\n",
      "502                         2018-12-11-18-36-07_L7.jpg      1\n",
      "503                         2018-12-11-19-04-26_S2.jpg      0\n",
      "504                         2018-12-12-16-03-10_S2.jpg      0\n",
      "..                                                 ...    ...\n",
      "646                         2021-09-21-19-04-08_S2.jpg      1\n",
      "647                         2021-09-26-19-04-09_S2.jpg      1\n",
      "648                         2021-10-01-19-04-08_S2.jpg      1\n",
      "649                         2021-10-11-19-04-07_S2.jpg      1\n",
      "650                         2021-12-15-19-04-20_S2.jpg      1\n",
      "\n",
      "[151 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converted the sorted column to string otherwises data generator will not work\n",
    "df[\"Sorted\"]=df[\"Sorted\"].astype(str)\n",
    "# Split the dataframe into a train and test set into a .75 and .25 training and test set respectively\n",
    "traindf=df.iloc[:500,:] # get the first 500 rows\n",
    "testdf=df.iloc[500:,:] # get the  remaining 150 rows\n",
    "\n",
    "# Get the x and y column names from the csv file\n",
    "x_col_name=df.columns[0]\n",
    "y_col_name=df.columns[1]\n",
    "\n",
    "print(traindf)\n",
    "print(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf669819",
   "metadata": {},
   "source": [
    "## Flow the images from the dataframe\n",
    "- resize the images from 934 x 294 to 900x294\n",
    "- shuffle the images\n",
    "- divide the data into a training and validation subset\n",
    "- set a random seed\n",
    "- set the column names to check \n",
    "\n",
    "1. TASK: investigate class_mode\n",
    "2. TASK: modify the images target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b553451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=dataset_path,\n",
    "x_col=x_col_name, #image filenames\n",
    "y_col=y_col_name,   # class names in this case good/bad\n",
    "subset=\"training\",\n",
    "batch_size=37,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(900,250))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5232b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=train_datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=dataset_path,\n",
    "x_col=x_col_name, #image filenames\n",
    "y_col=y_col_name,   # class names in this case good/bad\n",
    "subset=\"validation\", #only difference is this\n",
    "batch_size=37, #296/8=37\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(900,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc3633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 151 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=testdf,\n",
    "directory=\"./images/\",\n",
    "x_col=x_col_name, #image filenames\n",
    "y_col=None,\n",
    "batch_size=14, #98/7=14\n",
    "seed=42,\n",
    "shuffle=False,  #shuffle must be false for validation dataset otherwise labels will not match\n",
    "class_mode=None,\n",
    "target_size=(900,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e874f",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "Create a simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825ea7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_model():\n",
    "#     model =  keras.Sequential()\n",
    "#     model.add(Conv2D(32,kernel_size=(3,3), padding= 'same',activation='relu',input_shape=(900, 250, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv2D(32, (3, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Conv2D(64, (3, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(512))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "#     model.compile(optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec859eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(900, 250, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a595226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 95s 8s/step - loss: 0.7173 - accuracy: 0.6143 - val_loss: 0.6817 - val_accuracy: 0.6892\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.6639 - accuracy: 0.7218 - val_loss: 0.5823 - val_accuracy: 0.8243\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 88s 9s/step - loss: 0.6189 - accuracy: 0.8182 - val_loss: 0.5647 - val_accuracy: 0.7162\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.5940 - accuracy: 0.8459 - val_loss: 0.6407 - val_accuracy: 0.8514\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.5758 - accuracy: 0.8733 - val_loss: 0.6386 - val_accuracy: 0.8514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f2dbab93c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model()\n",
    "model.fit(train_generator,\n",
    "                    validation_data = train_generator,\n",
    "                    steps_per_epoch = train_generator.n//train_generator.batch_size,\n",
    "                    validation_steps = valid_generator.n//valid_generator.batch_size,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1758970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 10s 3s/step - loss: 0.6201 - accuracy: 0.8500\n",
      "Test loss: 0.6200941205024719\n",
      "Test accuracy: 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(valid_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3542ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test scores to a file\n",
    "import csv\n",
    "csv_file_path=os.getcwd()+os.sep+\"test_results\"+os.sep+\"modelScores.csv\"\n",
    "if not os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as outcsv:\n",
    "        writer = csv.writer(outcsv)\n",
    "        writer.writerow([\"Accuracy\", \"Test Loss\", \"Model Description\"])\n",
    "elif os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, 'a', newline='') as outcsv:\n",
    "            writer = csv.writer(outcsv)\n",
    "            writer.writerow([score[1], score[0], \"redid entire model after research\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  keras.Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), padding='same',\n",
    "#                  input_shape=(32,32,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6167b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f151b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
