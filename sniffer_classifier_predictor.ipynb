{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sniffer Classifer Predictor\n",
    "Use this notebook to run predictions with the sniffer classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"model_100_x_100\"\n",
    "model_path=os.getcwd()+ os.sep+\"models\"+os.sep+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 10, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                51216     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,642\n",
      "Trainable params: 70,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_path+os.sep+\"model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Variables\n",
    "Use these variables to change the prediction parameters for your CNN.\n",
    "- `dataset_path`: directory containing the unzipped imagery\n",
    "- `img_shape` : shape (width , height) your imagery will be resized to. These are inputs into the model. This must be the same size as the size you trained your model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=os.getcwd()+os.sep+\"test_images\"\n",
    "csv_name=\"mapped_test_dataset.csv\"\n",
    "csv_path=os.getcwd()+os.sep+csv_name\n",
    "img_shape=(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_img(image,img_shape:tuple)->list:\n",
    "    \"\"\"returns np.array resized to (1,img_shape,3)\"\"\"\n",
    "    img=image.resize(img_shape,Image.ANTIALIAS)\n",
    "    imgArray = np.asarray(img)\n",
    "    imgArray=imgArray.reshape((1,)+img_shape+(3,))# Create batch axis\n",
    "    return imgArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_encode_labels(df:'pandas.core.frame.DataFrame',labels=[\"good\",\"bad\"]):\n",
    "    \"\"\" Returns the modified dataframe with the labels one hot encoded\"\"\"\n",
    "    mapping = {}\n",
    "    for x in range(len(labels)):\n",
    "        mapping[labels[x]] = x\n",
    "    # outputs {'good': 0, 'bad': 1}\n",
    "    # Replace each label in sorted with corresponding one hot encoded label\n",
    "    for x in range(len(df['Sorted'])):\n",
    "        df['Sorted'][x] = mapping[df['Sorted'][x]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_df(csv_path:str):\n",
    "    \"\"\"Returns a cleaned dataframe with the labels one hot encoded\n",
    "    Use this function when you have a dataframe with correct labels\n",
    "    you want to compare the model against\n",
    "    \"\"\"\n",
    "    # Read in the labeled_df that the model has never seen before\n",
    "    df=pd.read_csv(csv_path)\n",
    "    if \"index\" in df.columns:\n",
    "        print(\"Dropping column index\")\n",
    "        df.drop(['index'],axis=1,inplace=True)\n",
    "    if \"Unnamed: 0\"in df.columns:\n",
    "        print(\"Dropping column Unnamed: 0\")\n",
    "        df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "    # one hot encode the labels in the \"sorted\" if they aren't already\n",
    "    if df['Sorted'].dtypes !='int64':\n",
    "        df=one_encode_labels(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_ready_data(dataset_path:str,img_shape:tuple):\n",
    "    \"\"\"returns a numpy array of the shape (number_images,img_shape,3)\"\"\"\n",
    "    images=[]\n",
    "    for image in os.listdir(dataset_path):\n",
    "        img=Image.open(dataset_path+os.sep+image)\n",
    "        img_array=pre_process_img(img,img_shape)\n",
    "        images.append(img_array)\n",
    "    data=np.vstack(images)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data:np.array):\n",
    "    \"\"\"Returns a numpy array of the predicted labels\"\"\"\n",
    "    predictions=model.predict(data)\n",
    "    prediction_labels=[pred.flatten().argmax(axis=0) for pred in predictions]\n",
    "    # Converted to float....\n",
    "    # prediction_labels=np.array(prediction_labels,dtype='uint8')\n",
    "    prediction_labels=np.array(prediction_labels,dtype='float')\n",
    "    print(type(prediction_labels))\n",
    "    return prediction_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=create_prediction_ready_data(dataset_path,img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_labels=get_predictions(data)\n",
    "prediction_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_labels[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column Unnamed: 0\n"
     ]
    }
   ],
   "source": [
    "# Read the correct labels from the dataframe\n",
    "df=read_labeled_df(csv_path)\n",
    "labels=df[\"Sorted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110   0]\n",
      " [ 13  56]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 24.0, 'Predicted')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=confusion_matrix(labels,prediction_labels)\n",
    "print(cm)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,fmt='g')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on a Single Image\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "image_path=r\"C:\\Users\\Sharon\\Downloads\\ob-20220412T220737Z-001\\ob\"+os.sep+\"2017-09-25-18-52-27_L8_rgbr.jpg\"\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    image_path, target_size=(100,100))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "np.array(img_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=model.predict(np.array(img_array) )\n",
    "reverse_mapping={0:\"good\",1:\"bad\"}\n",
    "label=reverse_mapping[prediction.flatten().argmax(axis=0)]\n",
    "label"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d2172767698a5f3d02b8c0066e6c8964018f76571aae7a5af18f1bff83069ee"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
